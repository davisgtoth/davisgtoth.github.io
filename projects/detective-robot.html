<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>detective_robot - Davis Toth Portfolio</title>
    <link rel="stylesheet" href="../css/main.css">
    <link rel="stylesheet" href="../css/navbar.css">
</head>

<body class="project-page">
    <div class="navbar" id="navbar">
        <div class="nav-left">
            <a href="../index.html">
                <p>Davis Toth Portfolio</p>
            </a>
        </div>
        <div class="nav-right">
            <a href="../index.html#about">about</a>
            <div class="dropdown">
                <a href="../index.html#projects">projects</a>
                <div class="dropdown-content">
                    <a href="../projects/wireless-drone.html">wireless_drone/</a>
                    <a href="../projects/ac-ionic-thruster.html">ac_ionic_thruster/</a>
                    <a href="../projects/detective-robot.html">detective_robot/</a>
                    <a href="../projects/mario-kart-robot.html">mario_kart_robot/</a>
                    <a href="../projects/assembly-clock.html">assembly_clock/</a>
                </div>
            </div>
            <a href="../resume.pdf" target="_blank">resumé</a>
        </div>
    </div>

    <main class="project-page">
        <div class="project-hero">
            <h3 class="hero-title">
                <span id="typed-text"></span><span class="cursor"></span>
            </h3>
            <video class="hero-media" autoplay muted loop playsinline poster="../assets/353/hero.jpg">
                <source src="../assets/353/hero_clip.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <div class="scroll-arrow" id="scrollArrow"></div>
        </div>

        <section class="project-section">
            <div class="project-text">
                <h2>Objective</h2>
                <p>
                    The goal was to build a detective, not just a robot. This project involved programming a fully
                    autonomous agent within a Gazebo simulation to crack a mystery. Developed in a Linux environment,
                    interfacing via ROS and scripted in Python, the robot had to navigate a complex map, autonomously
                    dodging traffic and NPCs (including Baby Yoda!), while hunting for clues. Success relied on devising
                    robust control algorithms to maneuver the map without collisions, while simultaneously deciphering
                    clues.
                </p>
            </div>
            <div class="project-image">
                <figure>
                    <img src="../assets/353/objective.png" alt="Obstacle Course Overview">
                    <figcaption>Obstacle Course Overview</figcaption>
                </figure>
            </div>
        </section>

        <section class="project-section reverse-mobile">
            <div class="slideshow-container" id="road-player">
                <div class="slides-wrapper">
                    <img class="slide-img" src="" alt="Algorithm Step">
                    <a class="prev">❮</a>
                    <a class="next">❯</a>
                </div>
                <div class="caption-container"></div>
            </div>
            <div class="project-text">
                <h2>Software Architecture</h2>
                <p>
                    The system is architected around a central finite state machine that dictates the robot's
                    behavior. This structure allows the agent to deploy specialized algorithms to handle the distinct
                    challenges presented by varied road, desert and mountain terrains, as well as the dynamic NPCs.
                </p>
                <p>
                    Navigation relies on reading the robot's live camera feed and publishing real-time steering commands
                    via ROS. Using this visual feedback, state-specific PID control loops and computer vision
                    algorithms are used to maneuver the robot. In parallel, a dedicated pipeline uses machine
                    learning to extract alphanumeric characters from detected clue boards.
                </p>
            </div>
        </section>

        <section class="project-section">
            <div class="project-text">
                <h2>Computer Vision</h2>
                <p>
                    To navigate the diverse map, the robot employed adaptive image processing techniques using OpenCV.
                    In high-contrast areas like the road, HSV color filtering effectively isolated the white lane
                    markings. The desert and mountain regions required a more robust approach, layering contour
                    detection and filtering after HSV masks to extract faint path boundaries.
                </p>
                <p>
                    When detected, distinct visual markers triggered transitions between environmental states, while
                    dynamic obstacles were managed via background subtraction. By filtering the static background to
                    isolate the pedestrian and truck, the robot could precisely localize these NPCs and execute the
                    necessary avoidance maneuvers.
                </p>
            </div>
            <div class="slideshow-container" id="desert-player">
                <div class="slides-wrapper">
                    <img class="slide-img" src="" alt="Algorithm Step">
                    <a class="prev">❮</a>
                    <a class="next">❯</a>
                </div>
                <div class="caption-container"></div>
            </div>
        </section>

        <section class="project-section reverse-mobile">
            <div class="slideshow-container" id="sign-player">
                <div class="slides-wrapper">
                    <img class="slide-img" src="" alt="Algorithm Step">
                    <a class="prev">❮</a>
                    <a class="next">❯</a>
                </div>
                <div class="caption-container"></div>
            </div>
            <div class="project-text">
                <h2>Clue Detection</h2>
                <p>
                    Mirroring the navigation framework, composite color masking and contour analysis
                    were used to isolate clue boards from the colourful backgrounds. Once a target was identified, the
                    image was segmented into individual characters and passed to a custom convolutional neural network
                    built with TensorFlow. Trained on a generated dataset, this deep learning model mapped raw pixel
                    data directly to alphanumeric text to solve the mystery.
                </p>
            </div>
        </section>

        <section class="project-section video-section">
            <div class="project-text centered-text">
                <h2>Case Closed</h2>
                <p>
                    Watch the full autonomous run below to see the robot navigate through the entire course!
                </p>
            </div>

            <div class="video-container">
                <div class="video-wrapper">
                    <iframe src="https://www.youtube.com/embed/KKQEBZ_tPzc" title="Detective Robot Demonstration"
                        frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen>
                    </iframe>
                </div>
            </div>
        </section>

        <section class="project-section resources-section">
            <div class="project-text">
                <h2>Resources</h2>
                <ul class="resource-list">
                    <li>
                        <a href="https://github.com/brooklynnae/BRODA_enph353" target="_blank">source_code.py</a>
                    </li>
                    <li>
                        <a href="https://github.com/davisgtoth/broda_data" target="_blank">data_collection/</a>
                    </li>
                    <li>
                        <a href="https://docs.google.com/document/d/1lIr0DIiiIhA6k2XXk26dAM6Z52fce9OGYzp9jR6H_Ew/edit?usp=sharing"
                            target="_blank">final_report.pdf</a>
                    </li>
                </ul>
            </div>

            <div class="project-image" style="visibility: hidden; height: 0;"></div>
        </section>

    </main>

    <br>
    <div class="bottom-spacer-top"></div>
    <div class="horizontal-line"></div>
    <p class="footnote">This site is still in development</p>
    <div class="bottom-spacer-bottom"></div>
    <br>

    <script>
        document.addEventListener("DOMContentLoaded", function () {
            const text = "detective_robot/";   // the text to type
            const typedText = document.getElementById("typed-text");
            let index = 0;

            function typeChar() {
                if (index < text.length) {
                    typedText.textContent += text.charAt(index);
                    index++;
                    setTimeout(typeChar, 120);  // typing speed (ms per character)
                }
            }

            typeChar();
        });
    </script>

    <script src="../javascript/scroll-indicator.js"></script>
    <script src="../javascript/scenario-player.js"></script>

</body>

</html>